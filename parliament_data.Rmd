---
title: "Parliament Data"
date: "AT 2023"
output: html_document
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = FALSE, warning = FALSE) 
```

## Introduction

## Data

## Part One: Retrieving Primary Data from UK Parliament API

### Oral and Written Questions

First, we retrieve the primary data from Parliament's API, including oral and written questions. Since the api is constantly updated with the latest questions asked, we set an end date of 31/12/2023 to keep results consistent through different runs.

By running the request in the API development hub, there are a total of 30878 entries of oral questions and 490441 entries of written questions. For oral questions, we set the take parameter to the maximum limit of 100 and loop through the entries by increasing the skip parameter. For written questions, there is no stated limit of the take parameter but through experimentation, setting the take parameter to 10000 strikes the balance between stability and speed. However, due to the large number of requests for written questions, the response sometimes unpredictably returns an error. To resolve this issue, we check the status code of each response, when it returns of a status code that is not 200, the programme will break from the current loop and print the request URL and its parameters that trigger the error. We can then manually adjust the skip parameter to continue the loop from the last successful request.

The oral and written question APIs differ slightly in field names and in field content. In each oral question asked, there is a field detailing the information of the MP who asked the question, however, in written questions, this field is empty. To keep the the data consistent, we will only keep the MP Id for each question for now, and retrieve the MP information in the next step using the MP API. To reduce data size, we will also only keep the following columns: Id, QuestionText, TabledWhen, AnsweringBodyId, AskingMemberId, AnsweringBody for both oral and written questions.

After retrieving the final tibbles, we will save the to .rds files for future use.

```{r retrieve_primary_data}

library(httr)
library(jsonlite)
library(tidyverse)

# scraping code below is commented out due to extremely long run time
if (FALSE) {
  
  # set the base URL and end date
  end_date <- "2023-12-31"
  base_url_oral <- "https://oralquestionsandmotions-api.parliament.uk/oralquestions/list"
  take <- 100
  num_response <- 30878
  num_request <- ceiling(num_response / take) # number of times to loop through the request
  
  # set the tibble to store all the results from each run
  oral_tibble <- tibble()
  
  # loop through request to build the oral tibble
  for (i in 0:(num_request - 1)) {
    skip <- i * take
    query <- sprintf("%s?parameters.answeringDateEnd=%s&parameters.skip=%s&parameters.take=%s", base_url_oral, end_date, skip, take)
    r <- GET(query)
    # check if the query is successful, print the parameters for unsuccessful queries
    if (status_code(r) != 200) {
      print("Error")
      print(skip)
      break
    }
    r_json <- fromJSON(rawToChar(r$content))
    r_tibble <- as_tibble(r_json$Response) |> 
      select(Id, QuestionText, TabledWhen, AnsweringBodyId, AskingMemberId, AnsweringBody) # select key rows
    oral_tibble <- oral_tibble |> bind_rows(r_tibble) # append to overall tibble
    Sys.sleep(1) # sleep for 1 second to avoid rate limit
  }
  
  # base URL for written questions
  base_url_written <- "https://questions-statements-api.parliament.uk/api/writtenquestions/questions"
  written_take <- 10000
  written_response <- 490441 # by observing the API response
  written_request <- ceiling(written_response / written_take) # number of times to loop through the request
  
  # set the tibble to store all the results from each run
  written_tibble <- tibble()
  
  # suppress scientific notation
  options(scipen = 999)
  
  # loop through request to build the written tibble
  for (i in 0:(written_request - 1)) {
    skip <- i * written_take
    query <- sprintf("%s?tabledWhenTo=%s&skip=%s&take=%s", base_url_written, end_date, skip, written_take)
    print(query)
    r <- GET(query)
    # check if the query is successful, print the parameters for unsuccessful queries
    if (status_code(r) != 200) {
      print("Error")
      print(skip)
      break
    }
    r_json <- fromJSON(rawToChar(r$content))
    r_tibble <- as_tibble(r_json$results$value) |> 
      select(id, questionText, dateTabled, answeringBodyId, answeringBodyName, askingMemberId) # select key rows
    written_tibble <- written_tibble |> bind_rows(r_tibble) # append to overall tibble
    print(i)
    Sys.sleep(5) # sleep for 5 seconds to avoid rate limit
}

# save both tibbles in .rds formats
saveRDS(oral_tibble, "data/oral_tibble.rds")
saveRDS(written_tibble, "data/written_tibble.rds")
}


```

### Filtering and Classifying Questions

Now we have the oral and written questions, we need to differentiate questions that are about economic issues and questions about health and welfare issues. First, we merge oral and written tibbles and add one column to store if each question is oral or written

There can be many strategies when it comes to filter the questions that are useful for our purpose. The most straightforward way is to filter the questions based on the answering bodies they are addressed to. However, dividing the questions purely based on the answering body proves to be less effective. This is largely because there are a total of 52 answering bodies and many of them do not have a clear focus on either economic or health and welfare issues. However, there are departments that are dedicated towards economic issues and health and welfare issues. They are:

|                                        |                                                            |
|-----------------------------|-------------------------------------------|
| Economics related Departments          | Treasury, HM Treasury                                      |
| Health and Welfare related Departments | Department of Health and Social Care, Department of Health |

Below are the step by step instructions on how the questions will be divided to two categories:

1.  Add one column to the tibble called "Issue Type" (Economic/Health and Welfare)
2.  Reference the table above, mark the questions addressed to the corresponding answering bodies
3.  For the questions that are not addressed to the answering bodies above, we will use the question text to determine which category the question belongs to. We will create a list of keywords that are related to economic issues and health and welfare issues. If the question text contains any of the keywords, we will mark the question as economic or health and welfare accordingly. The keywords are generated by ChatGPT 4 and double checked before being used.
4.  If the question text does not contain any of the keywords, we will mark the question as "Other". (this process may take longer to run)
5.  For text questions with words from both keywords list, we will mark the questions as "Pending" and duplicate them (one makred as Health and Welfare, one makred as Economic).

```{r filtering_and_classifying_questions}

# read the two tibbles from the .rds files
oral_tibble <- readRDS("data/oral_tibble.rds")
written_tibble <- readRDS("data/written_tibble.rds")

# merge two tibbles and add a column to indicate if the question is oral or written
oral_tibble <- oral_tibble |> mutate(QuestionType = "oral") 
written_tibble <- written_tibble |> mutate(QuestionType = "written")
# update the column names of written tibble to match oral tibble
colnames(written_tibble) <- c("Id", "QuestionText", "TabledWhen", "AnsweringBodyId", "AnsweringBody", "AskingMemberId", "QuestionType" )

# merge the two tibbles
questions_tibble <- oral_tibble |> bind_rows(written_tibble)

# Step one: add one column to the tibble called "Issue Type" (Economic/Health and Welfare)
questions_tibble <- questions_tibble |> mutate(IssueType = NA)

# Step two: Mark Economics and Health and Welfare related questions based on the answering bodies
# Economics related Departments: Treasury, HM Treasury, Department for Business and Trade
# Health and Welfare related Departments: Department of Health and Social Care, Department of Health
questions_tibble <- questions_tibble |> 
  mutate(IssueType = case_when(
  AnsweringBody == "Treasury" ~ "Economic",
  AnsweringBody == "HM Treasury" ~ "Economic",
  AnsweringBody == "Department of Health and Social Care" ~ "Health and Welfare",
  AnsweringBody == "Department of Health" ~ "Health and Welfare"
 ))

# Step three and four: keyword based classification

economic_keywords <- c(
  "economy", "inflation", "gdp", "unemployment", "fiscal policy", 
  "budget", "monetary policy", "investment", "taxation", 
  "debt", "financial markets", "economic growth", "currency", 
  "interest rates", "stock market", "deficit", "consumer spending", 
  "business regulation", "exchange rate", "economic development", 
  "banking", "financial crisis", "trade deficit", "inflation rate", 
  "economic policy", "entrepreneurship", "business growth", "market trends", 
  "economic stability", "investment strategy", "economic forecast", 
  "financial planning", "economic recovery", "economic reform",
  "housing market", "exports", "imports", "economic impact", "fiscal deficit",
  "labour market", "economic inequality", "economic sustainability", 
  "economic integration", "corporate tax", "economic diversification", 
  "economic sanctions", "economic indicators", "economic resilience"
)

health_welfare_keywords <- c(
  "nhs", "healthcare", "social care", "mental health", 
  "medicine", "public health", "insurance", "hospital", "disability", 
  "elderly care", "child welfare", "health policy", "vaccination", 
  "disease", "treatment", "patient care", "health education", 
  "medical research", "healthcare funding", "health insurance", 
  "preventive care", "health crisis", "nutrition", "medical ethics", 
  "health equity", "mental illness", "healthcare technology", "pandemic", 
  "health screening", "medical training", "public safety", "health regulations", 
  "mental wellness", "community health", "health services", "care homes",
  "public welfare", "health budget", "mental healthcare", "medical staffing",
  "health reforms", "social security", "child healthcare", "wellbeing",
  "health expenditure", "health data", "clinical research", "patient rights"
)

library(tm)
# get the tibble rows with NA IssueType and perform standard text preprocessing
# remove punctuation, numbers and convert to lower case
untagged_tibble <- questions_tibble |> 
  filter(is.na(IssueType)) |> 
  mutate(QuestionText = str_remove_all(QuestionText, "[[:punct:]]")) |> 
  mutate(QuestionText = str_remove_all(QuestionText, "[[:digit:]]")) |> 
  mutate(QuestionText = tolower(QuestionText))

# define a function to categorise questions based on keywords
categorise_questions <- function(text, keywords_one, keywords_two) {
  if (any(str_detect(text, paste(keywords_one, collapse = "|")))) {
    if (any(str_detect(text, paste(keywords_two, collapse = "|")))) {
      return("Pending")
    } else {
      return("Economic")
    }
  } else if (any(str_detect(text, paste(keywords_two, collapse = "|")))) {
    if (any(str_detect(text, paste(keywords_one, collapse = "|")))) {
      return("Pending")
    } else {
      return("Health and Welfare")
    }
  } else {
    return("Other")
  }
}

# perform categorise function (This step may take longer to run)
untagged_tibble <- untagged_tibble |> 
  mutate(IssueType = sapply(QuestionText, categorise_questions, economic_keywords, health_welfare_keywords))

# Step 5, Duplicate "Pending" questions
# filter the tibble to get the questions marked as "Pending"
pending_questions <- untagged_tibble |> 
  filter(IssueType == "Pending")
# duplicate each row and change the IssueType to "Economic" and "Health and Welfare"
pending_questions <- pending_questions |>
  slice(rep(1:n(), each = 2))
pending_questions <- pending_questions |>
  mutate(IssueType = rep(c("Economic", "Health and Welfare"), length.out = nrow(pending_questions)))
  
# combine pending questions with tagged tibble
tagged_tibble <- untagged_tibble |> 
  filter(IssueType != "Pending") |> 
  bind_rows(pending_questions)

# combine tagged tibble with the questions tibble
questions_tibble <- questions_tibble |> 
  filter(!is.na(IssueType)) |> 
  bind_rows(tagged_tibble)
```

### MP Information

Each question within the two tables above contains the MP Id of the MP who asked the question. We will use this information to retrieve the MP information from the MP API. We will follow the steps below to retrieve the MP information:

1.  Merge oral and written tibbles and add one column to store if each question is oral or written
2.  Create a list of all unique MP Ids from the merged tibble
3.  Loop through all MP ids to retrieve target MP info from various MP API endpoints
4.  Create a list to store MP ids that failed to return responses
5.  Recheck the failed ids

We retrieve the following information for each MP:

| Information Retrieved                                     | Members API Used                      |
|-------------------------------------------|-----------------------------|
| Displayed Name, Gender, Latest Party, Constituency, House | /api/Members/{id}                     |
| Registered Interest                                       | /api/Members/{id}/RegisteredInterests |

The failed id list is empty, meaning that all requests were successful, we store the mp tibble again in the data folder.

```{r retrieve_mp_data}
# create a list of all unique MP Ids

# read the two tibbles from the .rds files
oral_tibble <- readRDS("data/oral_tibble.rds")
written_tibble <- readRDS("data/written_tibble.rds")

# merge two tibbles and add a column to indicate if the question is oral or written
oral_tibble <- oral_tibble |> mutate(QuestionType = "oral") 
written_tibble <- written_tibble |> mutate(QuestionType = "written")
# update the column names of written tibble to match oral tibble
colnames(written_tibble) <- c("Id", "QuestionText", "TabledWhen", "AnsweringBodyId", "AnsweringBody", "AskingMemberId", "QuestionType" )
# merge the two tibbles
questions_tibble <- oral_tibble |> bind_rows(written_tibble)

# create a list of all unique MP Ids
mp_ids <- questions_tibble |> distinct(AskingMemberId) |> pull(AskingMemberId)

# create a new tibble to store MP information and set column names
mp_tibble <- tibble(
  
  AskingMemberID = NA,
  Name = NA,
  Gender = NA,
  LatestParty = NA,
  Membership = NA,
  House = NA,
  RegisteredInterest = NA
)

# api calls commented out due to long run time
if (FALSE) {
  # create a function to retrieve a single MP's information
  base_url <- "https://members-api.parliament.uk/api/Members"
  
  failed_ids <- list()
  
  # loop through all mp ids and retrieve MP's info, fill in the tibble
  for (mp_id in mp_ids) {
    
    # a result variable to keep track of the success of current MP call
    fail <- NA
    
    # initialize all target variables to NA
    AskingMemberID <- mp_id
    Name <- NA
    Gender <- NA
    LatestParty <- NA
    Membership <- NA
    House <- NA
    RegisteredInterest <- NA
    
    # first retrieve the Displayed Name, Gender, Latest Party, Membership, House
    query_one <- sprintf("%s/%s", base_url, mp_id)
    r_one <- GET(query_one)
    if (status_code(r_one) == 200) {
      r_json <- fromJSON(rawToChar(r_one$content))
      Gender <- r_json$value$gender
      Name <- r_json$value$nameDisplayAs
      LatestParty <- r_json$value$latestParty$name
      Membership <- r_json$value$latestHouseMembership$membershipFrom
      House <- r_json$value$latestHouseMembership$house
    } else {
      print("Error")
      fail <- mp_id
    }
    
    # check_failure
    if (!is.na(fail)) {
      # add fail to failed_ids
      failed_ids <- c(failed_ids, fail)
      next
    } 
    
    # then retrieve the Registered Interest
    query_two <- sprintf("%s/%s/RegisteredInterests", base_url, mp_id)
    r_two <- GET(query_two)
    if (status_code(r_two) == 200) {
      r_json <- fromJSON(rawToChar(r_two$content))
      RegisteredInterest <- r_json$value$name
    } else {
      print("Error")
      fail <- mp_id
    }
    
    # check failure
     if (!is.na(fail)) {
       # add fail to failed_ids
      failed_ids <- c(failed_ids, fail)
      next
     } 
    
    mp_tibble <- add_row(mp_tibble, AskingMemberID = AskingMemberID, Name = Name, Gender = Gender,
                         LatestParty = LatestParty, Membership = Membership, 
                         House = House, RegisteredInterest = RegisteredInterest)
    
    # print success message followed by mp id
    print(sprintf("Success for ID%s", mp_id))
  }
  
  # save the mp tibble to data folder
  saveRDS(mp_tibble, "data/mp_tibble.rds")
}

```

### Clean up the MP Data

Now we perform some clean up to the MP data. The tibble now has multiple rows for MPs with more than one registered interests, each row records one registered interest of a single MP. We will merge the rows of the same MP and combine the registered interests into one column. We are interested in interest category of the MPs' registered interests. Hence, when combining each row, we record the interest category number for each MP and put all numbers into a string. The category number is entailed in the name of the registered interest, either before the "." symbol or after the word "category". We will use this logic to extract the category number.

N.B. When collapsing the list into a string, NA values are transformed to the literal string of NA, hence in the final stage, we will replace strings of NA with actual NA values.

```{r clean_mp_data}

# read the mp tibble from the .rds file
mp_tibble <- readRDS("data/mp_tibble.rds")

# for each mp id, put all registered interests into a list and collapse the rows, then unnest the list
mp_tibble <- mp_tibble |> 
  group_by(AskingMemberID) |> 
  mutate(RegisteredInterest = list(RegisteredInterest)) |> # combine all registered interests into a list
  distinct(AskingMemberID, .keep_all = TRUE)  # remove duplicated rows
  
# collapse the list into a single string
mp_tibble <- mp_tibble |> 
  mutate(RegisteredInterest = map_chr(RegisteredInterest, ~paste(., collapse = ", "))) |> 
  unnest(cols = c(RegisteredInterest)) # unnest the list

# a function to convert the string to a string of numbers (retrieving category number)
convert_to_number <- function(x) {
  
  # if the field is NA, return NA
  if (x == "NA") {
    return(NA)
  }
  
  # initialize a list to store the numbers
  numbers <- list()
  
  # find all occurrences of the pattern "category" followed by a number
  category_matches <- str_extract_all(x, "Category\\s\\d+")
  for (match in category_matches) {
    number <- str_extract(match, "\\d+")
    numbers <- c(numbers, number)
  }
  
  # find all occurrences of the pattern number followed by a "."
  dot_matches <- str_extract_all(x, "\\d+\\.")
  for (match in dot_matches) {
    number <- str_extract(match, "\\d+")
    numbers <- c(numbers, number)
  }
  
  # delete duplicates of the list and convert to a string
  numbers <- numbers |> unique() |> paste(collapse = ", ")
  
  # return the list of numbers
  return(numbers)
}

# apply the function to each RegisteredInterest Row of the tibble
mp_tibble <- mp_tibble |> mutate(RegisteredInterest = sapply(RegisteredInterest, convert_to_number))

# delete the first row that is empty
mp_tibble <- mp_tibble[-1, ]

# change mptibble column name AskingMemberID
mp_tibble <- mp_tibble |> rename(AskingMemberId = AskingMemberID)

```

### Combine Tibble and Clean Up

Now we combine both tibble with the AskingMemberId Column. We will use the left_join function to combine the two tibbles. The left_join function will keep all rows of the primary tibble and add the columns of the secondary tibble to the primary tibble. Save the tibble file to the data folder.

We then perform some clean up to streamline the tibble and reduce the size of the tibble. These steps include:

1.  Delete columns Id, QuestionText, AnsweringBodyID, AskingMemberID, AnsweringBody. These columns are not needed for the analysis and by deleting them, we can work with a tibble much smaller in size. The tibble that does contain all these columns are saved in the data folder for future use.
2.  Convert TabledWhen chr format to a datetime format
3.  Remove the rows with IssueType = "Other" as these rows are not relevant to the analysis.

```{r combine_clean_tibble}
primary_tibble <- questions_tibble |>
  left_join(mp_tibble, by = "AskingMemberId")
primary_tibble
# Save the primary tibble to data folder
saveRDS(primary_tibble, "data/primary_tibble.rds")

primary_tibble <- readRDS("data/primary_tibble.rds")
# Delete columns Id, QuestionText, AnsweringBodyID, AskingMemberID, AnsweringBody
lite_tibble <- primary_tibble |> 
  select(-Id, -QuestionText, -AnsweringBodyId, -AskingMemberId, -AnsweringBody)

# Convert TabledWhen chr format to a datetime format and only keep the month and year of the date
lite_tibble <- lite_tibble |> 
  mutate(TabledWhen = as.Date(TabledWhen, format = "%Y-%m-%d"))

# Remove the rows with IssueType = "Other"
lite_tibble <- lite_tibble |> filter(IssueType != "Other")

# Change the colname TabledWhen to Date
lite_tibble <- lite_tibble |> rename(Date = TabledWhen)
```

## Part Two: Retrieving Secondary Data

### FTSE100 Data and GDP Data

```{r retrieve_secondary_data}
# import the FTSE100 Historical data and the quarterly GDP data from csv files in the data folder
ftse100 <- read_csv("data/FTSE100.csv", show_col_types = FALSE)
gdp <- read_csv("data/GDP.csv", show_col_types = FALSE)

# convert the date column of the FTSE100 data to a date format that matches that of the lite tibble
ftse100 <- ftse100 |> 
  mutate(Date = as.Date(Date, format = "%d/%m/%Y")) |> 
  mutate(Date = as.Date(Date, format = "%Y-%m-%d"))

# add one column "FTSEChange" to the ftse100 data, if column Change% is a number larger or equal than 0, Change = 1, else Change = 0 (this is done by detecting the "-" character)
ftse100 <- ftse100 |> 
  mutate(FTSEChange = ifelse(str_detect(`Change %`, "-"), 0, 1))
# Keep only the FTSEChange and Date Columns
ftse100 <- ftse100 |> select(FTSEChange, Date)


# delete the first 7 rows of the gdp data (they were notes about the dataset)
gdp <- gdp[-c(1:7), ]

# add one column "GDPChange" to the gdp data, if c olumn "Gross Domestic Product: Quarter on Quarter growth: CVM SA %" is a number larger or equal than 0, Change = 1, else Change = 0 (this is done by detecting the "-" character)
gdp <- gdp |> 
  mutate(GDPChange = ifelse(str_detect(`Gross Domestic Product: Quarter on Quarter growth: CVM SA %`, "-"), 0, 1))

# Keep only the GDPChange and Title Columns
gdp <- gdp |> select(GDPChange, Title) |> 
  rename(Quarter = Title)

# Merge data with the lite tibble
lite_tibble <- lite_tibble |> 
  left_join(ftse100, by = "Date")

# use lubridate to add a column "Quarter" to the lite tibble
lite_tibble <- lite_tibble |> 
  mutate(Quarter = quarter(Date, with_year = TRUE))

# convert the Quarter column to a character format
lite_tibble <- lite_tibble |> 
  mutate(Quarter = as.character(Quarter))

# for each Quarter, replace the "." with a " Q"
lite_tibble <- lite_tibble |> 
  mutate(Quarter = str_replace(Quarter, "\\.", " Q"))

# merge the lite tibble with the gdp data
lite_tibble <- lite_tibble |> 
  left_join(gdp, by = "Quarter")

# delete the Quarter column
lite_tibble <- lite_tibble |> 
  select(-Quarter)

# Create columns in lite tibble for each RegisteredInterest (10 in total)
lite_tibble <- lite_tibble |> 
  mutate(RegisteredInterest1 = ifelse(str_detect(RegisteredInterest, "1"), 1, 0)) |> 
  mutate(RegisteredInterest2 = ifelse(str_detect(RegisteredInterest, "2"), 1, 0)) |> 
  mutate(RegisteredInterest3 = ifelse(str_detect(RegisteredInterest, "3"), 1, 0)) |> 
  mutate(RegisteredInterest4 = ifelse(str_detect(RegisteredInterest, "4"), 1, 0)) |> 
  mutate(RegisteredInterest5 = ifelse(str_detect(RegisteredInterest, "5"), 1, 0)) |> 
  mutate(RegisteredInterest6 = ifelse(str_detect(RegisteredInterest, "6"), 1, 0)) |> 
  mutate(RegisteredInterest7 = ifelse(str_detect(RegisteredInterest, "7"), 1, 0)) |> 
  mutate(RegisteredInterest8 = ifelse(str_detect(RegisteredInterest, "8"), 1, 0)) |> 
  mutate(RegisteredInterest9 = ifelse(str_detect(RegisteredInterest, "9"), 1, 0)) |> 
  mutate(RegisteredInterest10 = ifelse(str_detect(RegisteredInterest, "10"), 1, 0))

# delete the RegisteredInterest column
lite_tibble <- lite_tibble |> 
  select(-RegisteredInterest)


```

### Scrape wikipedia page to get the region for each constituency

```{r scrape_wikipedia}

library(rvest)

url <- "https://en.wikipedia.org/wiki/Constituencies_of_the_Parliament_of_the_United_Kingdom"
html_content <- rvest::read_html(url)

tables <- html_table(html_content, fill = TRUE)

# by observation, table 5, 6, 7, 8 are England, Scotland, Wales, Northern Ireland respectively
table_england <- tables[[5]]
table_scotland <- tables[[6]]
table_wales <- tables[[7]]
table_northern_ireland <- tables[[8]]

# get constituency columns of Scotland, Wales, Northern Ireland
constituency_scotland <- table_scotland |> 
  select(Constituency) |> 
  mutate(Region = "Scotland")

constituency_wales <- table_wales |>
  select(Constituency) |> 
  mutate(Region = "Wales")

constituency_northern_ireland <- table_northern_ireland |>
  select(Constituency) |> 
  mutate(Region = "Northern Ireland")

# get constituency columns and Region of England, bind the rows of the 4 tables
constituency_region <- table_england |> 
  select(Constituency, Region) |>
  rbind(constituency_scotland) |>
  rbind(constituency_wales) |>
  rbind(constituency_northern_ireland) |> 
  # change the Column name to Membership match the lite tibble
  rename(Membership = Constituency)

# join the table with the lite tibble 
lite_tibble <- lite_tibble |> 
  left_join(constituency_region, by = "Membership")




# Include the Lord Membership in Region
# find all rows where Region is NA
modify_region <- lite_tibble |> 
  filter(is.na(Region)) |> 
  mutate(Region = Membership)
# combine two tibbles
lite_tibble <- lite_tibble |> 
  filter(!is.na(Region)) |> 
  bind_rows(modify_region)

# convert all columns to categorical variables aside from "Date", "Name" using a loop
for (i in 1:ncol(lite_tibble)) {
  if (names(lite_tibble)[i] != "Date" & names(lite_tibble)[i] != "Name") {
    lite_tibble[[i]] <- as.factor(lite_tibble[[i]])
  }
}

```

## Part Three: Analysis and Visualisation

## Data Exploration and Visualisation for Binary Factors

```{r data_exploration_binary_factors}

# Create the horizontal line to show the overall ratio of Economic and Health/Welfare related questions
overall_ratio <- lite_tibble |> 
  group_by(IssueType) |> 
  summarise(overall_ratio = n()) |> 
  mutate(overall_ratio = overall_ratio / sum(overall_ratio))

# get overall_ratio when IssueType is "Health/Welfare"
overall_ratio_health <- overall_ratio |> 
  filter(IssueType == "Health and Welfare")

# define horizontal line
horizontal_line <- 
  geom_hline(yintercept = overall_ratio_health$overall_ratio, linetype = "dashed", color = "black") 
  

# Visualise the ratio of Economics and Health/Welfare related questions over Gender
  
gender <- ggplot(lite_tibble, aes(x = Gender, fill = IssueType)) +
  geom_bar(position = "fill", width = 0.5) +
  labs(title = "Issue Type Distribution by Gender", x = "Gender", y = "Issue Type Distributin") + 
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  horizontal_line +
  geom_text(aes(x = 0.1, y = overall_ratio_health$overall_ratio + 0.03, label = "Overall Ratio"), hjust = 0)


# Visualise the ratio of Economics and Health/Welfare related questions over House

house <- ggplot(lite_tibble, aes(x = House, fill = IssueType)) +
  geom_bar(position = "fill", width = 0.5) +
  labs(title = "Issue Type Distribution by House", x = "House", y = "Issue Type Distributin") + 
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  horizontal_line +
  geom_text(aes(x = 0.1, y = overall_ratio_health$overall_ratio + 0.03, label = "Overall Ratio"), hjust = 0)
  
# Visualise the ratio of Economics and Health/Welfare related questions over QuestionType

type <- ggplot(lite_tibble, aes(x = QuestionType, fill = IssueType)) +
  geom_bar(position = "fill", width = 0.5) +
  labs(title = "Issue Type Distribution by Question Type", x = "Question Type", y = "Issue Type Distributin") + 
  # miminalistic theme
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  horizontal_line +
  geom_text(aes(x = 0.1, y = overall_ratio_health$overall_ratio + 0.03, label = "Overall Ratio"), hjust = 0)

# Visualise the ratio of Economics and Health/Welfare related questions over FTSEChange

# select non-NA rows
FTSE <- lite_tibble |> 
  filter(!is.na(FTSEChange)) |> 
  ggplot(aes(x = FTSEChange, fill = IssueType)) +
    geom_bar(position = "fill", width = 0.5) +
    labs(title = "Issue Type Distribution by FTSE Change", x = "FTSE100 Change", y = "Issue Type Distributin") + 
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5)) +
    horizontal_line +
    geom_text(aes(x = 0.1, y = overall_ratio_health$overall_ratio + 0.03, label = "Overall Ratio"), hjust = 0)

# Visualise the ratio of Economics and Health/Welfare related questions over GDPChange

GDP <- lite_tibble |> 
  filter(!is.na(GDPChange)) |> 
  ggplot(aes(x = GDPChange, fill = IssueType)) +
    geom_bar(position = "fill", width = 0.5) +
    labs(title = "Issue Type Distribution by GDP Change", x = "GDP Change", y = "Issue Type Distributin") + 
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5)) +
    horizontal_line +
    geom_text(aes(x = 0.1, y = overall_ratio_health$overall_ratio + 0.03, label = "Overall Ratio"), hjust = 0)

# Visualise the ratio of Economics and Health/Welfare related questions over Region

# get the order of regions
prop_health <- lite_tibble |> 
  group_by(Region) |> 
  summarise(health_proportion = sum(IssueType == "Health and Welfare") / n())

ordered_regions <- prop_health |> 
  arrange(desc(health_proportion)) |> 
  pull(Region)

# assign the order to the factor
lite_tibble$Region <- factor(lite_tibble$Region, levels = ordered_regions)

region <- lite_tibble |> 
  filter(!is.na(Region)) |> 
  ggplot(aes(x = Region, fill = IssueType)) +
    geom_bar(position = "fill", width = 0.5) +
    labs(title = "Issue Type Distribution by Region", x = "Region", y = "Issue Type Distributin") + 
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5)) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) + # rotate x axis text 
    horizontal_line +
    geom_text(aes(x = 0.1, y = overall_ratio_health$overall_ratio + 0.03, label = "Overall Ratio"), hjust = 0)
region
# Visualise the ratio of Economics and Health/Welfare related questions over Party

# get the order of parties, delete rows with less than 100 counts
prop_health <- lite_tibble |> 
  filter(!is.na(LatestParty)) |> 
  group_by(LatestParty) |> 
  filter(n() > 100) |> 
  summarise(health_proportion = sum(IssueType == "Health and Welfare") / n())
ordered_parties <- prop_health |>
  arrange(desc(health_proportion)) |> 
  pull(LatestParty)

# assign the order to the factor
lite_tibble$LatestParty <- factor(lite_tibble$LatestParty, levels = ordered_parties)

party <- lite_tibble |> 
  filter(!is.na(LatestParty)) |> 
  ggplot(aes(x = LatestParty, fill = IssueType)) +
    geom_bar(position = "fill", width = 0.5) +
    labs(title = "Issue Type Distribution by Party", x = "Party", y = "Issue Type Distributin") + 
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5)) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) + # rotate x axis text
    horizontal_line +
    geom_text(aes(x = 0.1, y = overall_ratio_health$overall_ratio + 0.03, label = "Overall Ratio"), hjust = 0)
party
# Visualise the ratio of Economics and Health/Welfare related questions over the RegisteredInterest1

graph_list <- list()

for (i in 1:10) {
  col_name <- paste0("RegisteredInterest", i)
  category_name <- paste0("Category ", i)
  title <- paste0("Issue Type Distribution by ", category_name, " Interest")
  graph <- lite_tibble |> 
    filter(!is.na(!!sym(col_name))) |>
    ggplot(aes(x = !!sym(col_name), fill = IssueType)) +
      geom_bar(position = "fill", width = 0.5) +
      labs(title = title, x = category_name, y = "Issue Type Distributin") + 
      theme_minimal() +
      theme(plot.title = element_text(hjust = 0.5)) +
      horizontal_line 
  graph_list[[i]] <- graph
} 

# display each graph in the graph list
for (i in 1:10) {
  print(graph_list[[i]])
}

# Visualise the ratio of Economics and Health/Welfare related questions over Year

# add a Year Column to the lite_tibble
lite_tibble$Year <- year(lite_tibble$Date)

# convert Year to a factor
lite_tibble$Year <- factor(lite_tibble$Year)

# groupby year 
year <- lite_tibble |> 
  ggplot(aes(x = Year, fill = IssueType)) +
    geom_bar(position = "fill", width = 0.5) +
    labs(title = "Health and Welfare Issue Type Proportion over Year", x = "Year", y = "Proportion") + 
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5)) +
    horizontal_line 
```

## Chi-Squared Test for Features

\``{r chi_squared_test} # suppress scientific notation options(scipen = 999) chisq.test(lite_tibble$IssueType, lite_tibble$Gender)$p.value chisq.test(lite_tibble$IssueType, lite_tibble$House)$p.value chisq.test(lite_tibble$IssueType, lite_tibble$)$p.value` \
## Predictive Modelling

```{r predictive_modelling}
# install.packages("randomForest")
# install.packages("caret")
# install.packages("ranger")
library(randomForest)
library(caret)


# delete NA value rows for Random Forest
cleaned_tibble <- lite_tibble %>%
  na.omit(c(QuestionType, Gender, LatestParty, Region, House, FTSEChange, GDPChange))

# split data into training and testing
set.seed(123)
training_indices <- sample(1:nrow(cleaned_tibble), 0.7 * nrow(cleaned_tibble))
train_data <- cleaned_tibble[training_indices, ]
test_data <- cleaned_tibble[-training_indices, ]

# build a random forest model
rf_model <- randomForest(IssueType ~ QuestionType + Gender + LatestParty + Region + House + FTSEChange + GDPChange,
                         data = train_data, 
                         na.action = na.exclude,  # Exclude NA values
                         importance = TRUE)


predictions <- predict(rf_model, test_data)
conf_matrix <- confusionMatrix(predictions, test_data$IssueType)
accuracy <- conf_matrix$overall["Accuracy"]
precision <- conf_matrix$byClass['Precision']
recall <- conf_matrix$byClass['Recall']
f1_score <- 2 * (precision * recall) / (precision + recall)

# print the results
print(conf_matrix)

# feature importance
varImpPlot(rf_model, sort = TRUE, n.var = 7, main = "Features Importance")
```

```{r predictive_modelling}
```

```{r predictive_modelling}
```
## Predictive Modelling

```{r predictive_modelling}
# Include the Lord Membership in Region
# find all rows where Region is NA
modify_region <- lite_tibble |> 
  filter(is.na(Region)) |> 
  mutate(Region = Membership)
# combine two tibbles
lite_tibble <- lite_tibble |> 
  filter(!is.na(Region)) |> 
  bind_rows(modify_region)

```
## Appendix: All code in this assignment

```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE} 
# this chunk generates the complete code appendix. 
# eval=FALSE tells R not to run (``evaluate'') the code here (it was already run before).
```
